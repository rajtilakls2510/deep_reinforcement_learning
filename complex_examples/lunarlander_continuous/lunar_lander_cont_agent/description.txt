Reward: Same as environment

Actor Network:
Input(8,) : State Input
Dense(256)
BatchNorm()
Dense(256)
BatchNorm()
Dense(256)
BatchNorm()
Dense(2)

Critic Network:
Input(8,) : State Input
Dense(192)
x1 = BatchNorm()

Input(2) : Action Input
x2 = Dense(64)

Concatenate(x1, x2)
Dense(256)
Dense(256)
Dense(1)

Training:
- Algorithm: DeepDPG
- Learn After Steps: 4
- Episodes: 2000
- Batch Size: 64
- Replay Size: 1_00_000
- Exploration Noise: Ornstein-Uhlenbeck
- Discount Factor: 0.99
- Tau: 0.001
- Actor Optimizer: Adam
- Actor Learning Rate: 0.0005
- Critic Optimizer: Adam
- Critic Learning Rate: 0.001

Results:
Training satisfactory. Agent is able to ultimately reach the goal.