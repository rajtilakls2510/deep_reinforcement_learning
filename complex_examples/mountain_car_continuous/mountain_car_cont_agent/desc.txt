Reward: Same as environment

Actor Network:
Input(2,) : State Input
Dense(32)
Dense(1)

Critic Network:
Input(2,) : State Input
x1 = Dense(32)

Input(1) : Action Input
x2 = Dense(32)

Concatenate(x1, x2)
Dense(256)
Dense(256)
Dense(1)

Training:
- Algorithm: DeepDPG
- Learn After Steps: 1
- Episodes: 300
- Batch Size: 64
- Replay Size: 1_00_000
- Exploration Noise: Ornstein-Uhlenbeck
- Discount Factor: 0.99
- Tau: 0.005
- Actor Optimizer: Adam
- Actor Learning Rate: 0.001
- Critic Optimizer: Adam
- Critic Learning Rate: 0.002

Results:
Training satisfactory. Agent is able to ultimately reach the goal.