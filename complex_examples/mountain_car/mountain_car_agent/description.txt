Reward:
r = (position - 0.5) / (|velocity| * 1000) where velocity>=0.1

Q Network:
Input(2)
Dense(32)
Dense(3)

Training:
- Algorithm: DeepQLearning
- Episodes: 300
- Batch Size: 64
- Replay Size: 1_00_000
- Exploration: 1
- Exploration Decay: 1.05
- Min Exploration: 0.01
- Exploration Decay After: 1
- Discount Factor: 0.99
- Update Target Network Parameters After: 1_000 steps
- Optimizer: Adam
- Learning Rate: 0.001

Results:
Training satisfactory. Agent is able to ultimately reach the goal.